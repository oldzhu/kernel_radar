# TAPRIO（sch_taprio）导致的 RCU stall / 类 soft-lockup 故障分析

[English](2026-02-04-f8850bc3986562f79619-taprio-rcu-stall-rca.md)

本文档解释：为什么该 repro 的 TAPRIO 调度参数会“饿死”RCU、它如何映射到相关函数，以及可选的修复/缓解方案各自的取舍。

范围 / 指针：
- Repro bundle 目录（因体积大通常被 git 忽略）：`kernel_radar/repro/f8850bc3986562f79619/`
- 串口自动化运行器（已跟踪）：`tools/run_repro_serial.py`（用法示例：`--bundle-dir kernel_radar/repro/f8850bc3986562f79619`）

> TL;DR
> - repro 配置了 `taprio` 的 schedule entry，并使用了非常小的 `interval`（例如 `0xff` = 255 **纳秒**）。
> - 纯软件（非 offload）TAPRIO 通过 **绝对时间** hrtimer（`advance_sched`）来推进 gate/schedule。
> - 当 interval 极小时，回调真正执行时往往已经 “now > end_time”，回调仍然返回 `HRTIMER_RESTART`，从而导致定时器几乎立刻再次触发。
> - 最终形成 **timer catch-up storm（追赶风暴）**，CPU 被高频定时器回调吞噬，RCU 无法获得足够的 quiescent state 进展，触发 `rcu_preempt detected stalls`。

---

## 1）现象特征（我们观察到什么）

在 KVM 下运行 repro 时，通常会看到：

- `rcu: INFO: rcu_preempt detected stalls ...`
- backtrace/stack 常包含定时器路径与 TAPRIO：
  - `advance_sched()`（TAPRIO 的 hrtimer 回调）
  - `__hrtimer_run_queues()` / `hrtimer_interrupt()`

有些报告里 stall 是在 `br_handle_frame` 等桥接/网络路径中“被报告出来”的；这通常是**检测点**而不是根因：RCU 报警的本质是某个 CPU 长时间无法进入/报告 quiescent state，而真正的 CPU hog 可能来自定时器风暴。

---

## 2）repro 配置了什么（输入）

syzkaller 程序（repro bundle 中的 `repro.syz`）通过 netlink `RTM_NEWQDISC` 安装 `taprio` qdisc，并下发 schedule entries，其中包含：

- `TCA_TAPRIO_SCHED_ENTRY_INTERVAL = 0xff`

在 `sch_taprio.c` 中，这个 interval 的解析是：

- `entry_policy[TCA_TAPRIO_SCHED_ENTRY_INTERVAL] = { .type = NLA_U32 }`
- `interval = nla_get_u32(tb[TCA_TAPRIO_SCHED_ENTRY_INTERVAL]);`

随后它会在实现中被当作 **纳秒** 使用。

---

## 3）TAPRIO 纯软件模式的“正常流程”（高层）

### 流程图：配置 → 定时器 → dequeue

```mermaid
flowchart TD
  A[userspace netlink RTM_NEWQDISC taprio] --> B[taprio_change()]
  B --> C[parse_taprio_schedule()]
  C --> D[parse_sched_list()]
  D --> E[fill_sched_entry(): interval, gate_mask, cmd]

  B --> F[setup_first_end_time(): first end_time, budgets]
  B --> G[taprio_get_start_time(): choose next cycle start]
  B --> H[taprio_start_sched(): start advance_timer]

  H --> I[hrtimer fires]
  I --> J[advance_sched(): compute next entry/end_time]
  J --> K[hrtimer_set_expires(end_time) + HRTIMER_RESTART]
  J --> L[__netif_schedule(): run qdisc dequeue]

  L --> M[taprio_dequeue(): choose skb based on gates]
```

### 关键点
在软件模式（无 full offload、无 txtime-assist）下，gate 的推进依赖定时器回调 **`advance_sched()`**。

---

## 4）病态行为从哪里来（RCA）

### 4.1 现有校验允许“非常小”的 interval

`fill_sched_entry()` 里只做了一个关键校验：interval 必须至少允许最小以太网帧（`ETH_ZLEN`）发出去：

- `min_duration = length_to_duration(q, ETH_ZLEN)`
- 若 `interval < min_duration` 则拒绝

其中 `length_to_duration()` 依赖 `picos_per_byte`（由链路速率推导）。在高速链路上，`min_duration` 可能非常小。

直觉示例：
- 10Gbps 下，1 byte 约 0.8ns。
- 60 bytes 约 48ns。
- 因此 255ns 很容易通过校验。

### 4.2 `advance_sched()` 使用绝对时间并总是重启

`advance_sched()` 计算下一次边界 `end_time` 后，会：

- `hrtimer_set_expires(&q->advance_timer, end_time);`
- `return HRTIMER_RESTART;`

这意味着：只要 end_time 计算出来了，定时器就会不断推进。

### 4.3 为什么会出现“追赶风暴（catch-up storm）”

当 interval 极小时：

1) 定时器计划在 `end_time` 触发。
2) 但 CPU 实际开始执行回调时，往往已经 `now > end_time`。
3) 回调仍将 expiry 设为“过去的时间点”，并返回 `HRTIMER_RESTART`。
4) hrtimer 看到这个 timer 已经过期，会几乎立刻再次触发回调。

于是形成一个近似紧环：
- hrtimer 触发
- `advance_sched()` 运行
- 立即再触发

其他子系统（包含 RCU 的进展）就被饿死。

### 失败环路图

```mermaid
flowchart TD
  T[hrtimer interrupt] --> A[advance_sched()]
  A --> B[compute end_time = entry.end_time + next.interval]
  B --> C{end_time <= now?}
  C -- yes --> D[hrtimer_set_expires(end_time in past)]
  D --> E[return HRTIMER_RESTART]
  E --> T

  C -- no --> F[program next expiry normally]
  F --> E
```

这就是核心 RCA：**用户可控的 interval 能驱动 hrtimer 形成忙循环**。

---

## 5）为什么 RCU 会报警（机制层面）

RCU 需要 CPU 周期性进入/报告 quiescent state，以推进 grace period。

定时器风暴会抑制：
- 进程调度
- softirq 的正常分配
- 合适的抢占/让出点

因此 RCU 会打印 stall：
- `rcu_preempt detected stalls`

即使 stall 在 `br_handle_frame` 等路径中被报告，CPU starvation 的根源仍可能是定时器风暴。

---

## 6）缓解/修复选项

这些选项可以叠加使用。

### 选项 A：对软件模式设置“合理的最小 interval”

思路：通用 CPU 上用纯软件方式实现 ~100ns 级 gate 调度没有实际意义，且容易成为 DoS 向量。

当满足：
- 不是 full offload
- 不是 txtime-assist

则施加更严格阈值，例如：
- `min_interval = max(min_frame_duration, 1us)`
- 若更小则通过 extack 直接拒绝配置

### 选项 B：将 advance timer 运行在 soft hrtimer 上下文

思路：即便 schedule 很激进，也尽量不要让推进逻辑在 hard IRQ 中执行，从而降低“硬中断占满 CPU”的风险。

实现思路：
- `HRTIMER_MODE_ABS_SOFT`

### 选项 C：在 `advance_sched()` 中实现 catch-up / skip-forward

思路：当系统已经“迟到”时（end_time 落后于 now），不要把 timer 重新设到过去；而是计算 **now 对应的 entry**，并把下一次触发设置在未来。

设计要点：
- 确保下一次 `end_time` **严格大于 now**
- 限制每次回调的工作量（避免长循环）

概念流程图：

```mermaid
flowchart TD
  T[advance_sched fired] --> N[now = taprio_get_time()]
  N --> S[compute next end_time normally]
  S --> C{end_time > now?}
  C -- yes --> ARM[arm timer at end_time]
  C -- no --> MAP[map now to cycle offset]
  MAP --> PICK[pick entry containing offset]
  PICK --> FUT[compute boundary strictly in future]
  FUT --> ARM
  ARM --> R[return HRTIMER_RESTART]
```

---

## 7）三种方案的优缺点与回归风险（A/B/C）

这三者并不互斥。通常较稳妥的落地路径是：先用 A+B 快速止血，再评估 C 作为更长期的语义修正。

### 选项 A（软件模式最小 interval）

优点：
- 防御强、实现简单：在配置阶段就阻断病态 schedule，直接消灭 timer storm。
- 影响面小：主要是 schedule 校验与 extack 报错。
- 性能可预测：避免把系统拖进不可控的高频 timer 行为。

缺点：
- 行为变化：以前能配置的极小 interval 现在会被拒绝。
- 阈值选择带“策略”属性（例如 1us 是否过于保守）。

可能的系统行为影响 / 回归点：
- 有人确实想在软件模式用亚微秒 interval：将无法配置。
- 常见 TAPRIO 场景（微秒~毫秒级 interval）基本不受影响。

### 选项 B（soft hrtimer）

优点：
- 降低最坏影响：避免在 hard IRQ 中长时间占用 CPU。
- 语义风险相对小：回调逻辑不变，只改变执行上下文。

缺点：
- 定时精度可能更差：soft timer 在系统繁忙时更易被延迟。
- 单独使用不一定彻底解决：interval 极小仍可能高频触发，只是没那么“灾难”。

可能的系统行为影响 / 回归点：
- 软件模式的 gate 切换抖动可能变大，尤其在 CPU 压力下。

### 选项 C（catch-up / skip-forward）

优点：
- 语义上更“正确”：系统迟到时能快速回到与 now 对齐的 entry，避免“设到过去又立刻触发”。
- 即使 interval 较小，也能避免忙循环式的追赶。
- 鲁棒性更强：适应 VM pause、CPU 争用、长时间关中断等情况。

缺点：
- 复杂度最高：需处理 base_time、cycle 边界、admin schedule 切换、cycle_time_extension 等细节。
- 更难保证无 bug：存在 subtle corner cases 风险。

可能的系统行为影响 / 回归点：
- 在过载下会“跳过”一些本应发生的 gate transition（这是设计选择：宁可丢精度也不要拖垮 CPU）。
- 若实现不谨慎，可能导致 gate 选择/切换时序错误，从而改变出包模式。

---

## 8）验证建议

- 验证原 repro 不再触发 RCU stall。
- 验证常规（微秒以上）schedule 不受影响。

